---
title: AudioContext.createBufferSource()
slug: Web/API/AudioContext/createBufferSource
tags:
  - API
  - 音源
  - 音频源
  - 音频节点
translation_of: Web/API/BaseAudioContext/createBufferSource
---
<p></p><section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/zh-CN/docs/Web/API/Web_Audio_API">Web Audio API</a></strong></li><li><strong><a href="/zh-CN/docs/Web/API/AudioContext"><code>AudioContext</code></a></strong></li><li class="toggle"><details open><summary>Constructor</summary><ol><li><a href="/zh-CN/docs/Web/API/AudioContext/AudioContext"><code>AudioContext()</code></a></li></ol></details></li><li class="toggle"><details open><summary>属性</summary><ol><li><span class="sidebar-icon"><span title="这是一个实验性的 API，请尽量不要在生产环境中使用它。"><i class="icon-beaker"> </i></span></span><a href="/zh-CN/docs/Web/API/AudioContext/baseLatency"><code>baseLatency</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/baseLatency$translate">[我来译!]</a></li><li><span class="sidebar-icon"><span title="这是一个实验性的 API，请尽量不要在生产环境中使用它。"><i class="icon-beaker"> </i></span></span><a href="/zh-CN/docs/Web/API/AudioContext/outputLatency"><code>outputLatency</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/outputLatency$translate">[我来译!]</a></li></ol></details></li><li class="toggle"><details open><summary>方法</summary><ol><li><a href="/zh-CN/docs/Web/API/AudioContext/close"><code>close()</code></a></li><li><span class="sidebar-icon"><span class="icon-only-inline" title="This is an obsolete API and is no longer guaranteed to work."><i class="icon-trash"> </i></span></span><s class="obsoleteElement"><a href="/zh-CN/docs/Web/API/AudioContext/createJavaScriptNode"><code>createJavaScriptNode()</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/createJavaScriptNode$translate">[我来译!]</a></s></li><li><a href="/zh-CN/docs/Web/API/AudioContext/createMediaElementSource"><code>createMediaElementSource()</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioContext/createMediaStreamDestination"><code>createMediaStreamDestination()</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioContext/createMediaStreamSource"><code>createMediaStreamSource()</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioContext/createMediaStreamTrackSource"><code>createMediaStreamTrackSource()</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/createMediaStreamTrackSource$translate">[我来译!]</a></li><li><span class="sidebar-icon"><span class="icon-only-inline" title="This is an obsolete API and is no longer guaranteed to work."><i class="icon-trash"> </i></span></span><s class="obsoleteElement"><a href="/zh-CN/docs/Web/API/AudioContext/createWaveTable"><code>createWaveTable()</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/createWaveTable$translate">[我来译!]</a></s></li><li><a href="/zh-CN/docs/Web/API/AudioContext/getOutputTimestamp"><code>getOutputTimestamp()</code></a> <a style="opacity: 0.5;" href="/zh-CN/docs/Web/API/AudioContext/getOutputTimestamp$translate">[我来译!]</a></li><li><a href="/zh-CN/docs/Web/API/AudioContext/suspend"><code>suspend()</code></a></li></ol></details></li><li class="toggle"><details open><summary>继承</summary><ol><li><a href="/zh-CN/docs/Web/API/EventTarget"><code>EventTarget</code></a></li></ol></details></li><li class="toggle"><details open><summary>Events</summary><ol><li><a href="/zh-CN/docs/Web/Events/statechange"><code>statechange</code></a></li><li><a href="/zh-CN/docs/Web/Events/complete"><code>complete</code></a></li><li><a href="/zh-CN/docs/Web/Events/ended"><code>ended</code></a></li><li><a href="/zh-CN/docs/Web/Events/message"><code>message</code></a></li><li><a href="/zh-CN/docs/Web/Events/loaded"><code>loaded</code></a></li><li><a href="/zh-CN/docs/Web/Events/audioprocess"><code>audioprocess</code></a></li><li><a href="/zh-CN/docs/Web/Events/nodecreate"><code>nodecreate</code></a></li></ol></details></li><li class="toggle"><details open><summary>Related pages for Web Audio API</summary><ol><li><a href="/zh-CN/docs/Web/API/AnalyserNode"><code>AnalyserNode</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioContextOptions"><code>AudioContextOptions</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioDestinationNode"><code>AudioDestinationNode</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioListener"><code>AudioListener</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioNode"><code>AudioNode</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioNodeOptions"><code>AudioNodeOptions</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioParam"><code>AudioParam</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioProcessingEvent"><code>AudioProcessingEvent</code></a></li><li><a href="/zh-CN/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a></li><li><a href="/zh-CN/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a></li><li><a href="/zh-CN/docs/Web/API/BiquadFilterNode"><code>BiquadFilterNode</code></a></li><li><a href="/zh-CN/docs/Web/API/ChannelMergerNode"><code>ChannelMergerNode</code></a></li><li><a href="/zh-CN/docs/Web/API/ChannelSplitterNode"><code>ChannelSplitterNode</code></a></li><li><a href="/zh-CN/docs/Web/API/ConstantSourceNode"><code>ConstantSourceNode</code></a></li><li><a href="/zh-CN/docs/Web/API/ConvolverNode"><code>ConvolverNode</code></a></li><li><a href="/zh-CN/docs/Web/API/DelayNode"><code>DelayNode</code></a></li><li><a href="/zh-CN/docs/Web/API/DynamicsCompressorNode"><code>DynamicsCompressorNode</code></a></li><li><a href="/zh-CN/docs/Web/API/GainNode"><code>GainNode</code></a></li><li><a href="/zh-CN/docs/Web/API/IIRFilterNode"><code>IIRFilterNode</code></a></li><li><a href="/zh-CN/docs/Web/API/MediaElementAudioSourceNode"><code>MediaElementAudioSourceNode</code></a></li><li><a href="/zh-CN/docs/Web/API/MediaStreamAudioDestinationNode"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href="/zh-CN/docs/Web/API/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode</code></a></li><li><a href="/zh-CN/docs/Web/API/OfflineAudioCompletionEvent"><code>OfflineAudioCompletionEvent</code></a></li><li><a href="/zh-CN/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a></li><li><a href="/zh-CN/docs/Web/API/OscillatorNode"><code>OscillatorNode</code></a></li><li><a href="/zh-CN/docs/Web/API/PannerNode"><code>PannerNode</code></a></li><li><a href="/zh-CN/docs/Web/API/PeriodicWave"><code>PeriodicWave</code></a></li><li><a href="/zh-CN/docs/Web/API/StereoPannerNode"><code>StereoPannerNode</code></a></li><li><a href="/zh-CN/docs/Web/API/WaveShaperNode"><code>WaveShaperNode</code></a></li></ol></details></li></ol></section><p></p>

<div>
<p><code>createBufferSource()</code> 方法用于创建一个新的<a href="/zh-CN/docs/Web/API/AudioBufferSourceNode" title="AudioBufferSourceNode 接口继承自,表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用"><code>AudioBufferSourceNode</code></a>接口, 该接口可以通过<a href="/zh-CN/docs/Web/API/AudioBuffer" title="这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。"><code>AudioBuffer</code></a> 对象来播放音频数据. <a href="/zh-CN/docs/Web/API/AudioBuffer" title="这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。"><code>AudioBuffer</code></a>对象可以通过<a href="/zh-CN/docs/Web/API/AudioContext/createBuffer" title="音频环境AudioContext 接口的 createBuffer() 方法用于新建一个空白的 AudioBuffer 对象，以便用于填充数据，通过 AudioBufferSourceNode 播放。"><code>AudioContext.createBuffer</code></a> 来创建或者通过 <a href="/zh-CN/docs/Web/API/AudioContext/decodeAudioData" title="这是从音频轨道创建用于web audio API音频源的首选方法。"><code>AudioContext.decodeAudioData</code></a>成功解码音轨后获取.</p>
</div>

<h2 id="语法">语法</h2>

<pre class="brush: js">var audioCtx = new AudioContext();
var source = audioCtx.createBufferSource();</pre>

<h2 id="返回">返回</h2>

<p>一个<a href="/zh-CN/docs/Web/API/AudioBufferSourceNode" title="AudioBufferSourceNode 接口继承自,表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用"><code>AudioBufferSourceNode</code></a>对象.</p>

<h2 id="例子">例子</h2>

<p>在这个例子中, 我们将会创建一个2秒的缓冲器,并用白噪音填充它, 然后通过<a href="/zh-CN/docs/Web/API/AudioBufferSourceNode" title="AudioBufferSourceNode 接口继承自,表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用"><code>AudioBufferSourceNode</code></a>来播放它. </p>

<div class="note">
<p><strong>Note</strong>: You can also <a href="http://mdn.github.io/audio-buffer/">run the code live</a>, or <a href="https://github.com/mdn/audio-buffer">view the source</a>.</p>
</div>

<pre class="brush: js;highlight[31]">var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
var button = document.querySelector(&apos;button&apos;);
var pre = document.querySelector(&apos;pre&apos;);
var myScript = document.querySelector(&apos;script&apos;);

pre.innerHTML = myScript.innerHTML;

// Stereo
var channels = 2;
// Create an empty two second stereo buffer at the
// sample rate of the AudioContext
var frameCount = audioCtx.sampleRate * 2.0;

var myArrayBuffer = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate);

button.onclick = function() {
  // Fill the buffer with white noise;
  //just random values between -1.0 and 1.0
  for (var channel = 0; channel &lt; channels; channel++) {
   // This gives us the actual ArrayBuffer that contains the data
   var nowBuffering = myArrayBuffer.getChannelData(channel);
   for (var i = 0; i &lt; frameCount; i++) {
     // Math.random() is in [0; 1.0]
     // audio needs to be in [-1.0; 1.0]
     nowBuffering[i] = Math.random() * 2 - 1;
   }
  }

  // Get an AudioBufferSourceNode.
  // This is the AudioNode to use when we want to play an AudioBuffer
  var source = audioCtx.createBufferSource();
  // set the buffer in the AudioBufferSourceNode
  source.buffer = myArrayBuffer;
  // connect the AudioBufferSourceNode to the
  // destination so we can hear the sound
  source.connect(audioCtx.destination);
  // start the source playing
  source.start();
}</pre>

<h2 id="规范">规范</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Specification</th>
   <th scope="col">Status</th>
   <th scope="col">Comment</th>
  </tr>
  <tr>
   <td><a lang="en" href="https://webaudio.github.io/web-audio-api/#widl-AudioContext-createBufferSource-AudioBufferSourceNode" class="external" hreflang="en">Web Audio API<br><small lang="zh-CN">createBufferSource()</small></a></td>
   <td><span class="spec-WD">Working Draft</span></td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="浏览器支持">浏览器支持</h2>

<div><div class="warning notecard"><strong><a href="https://github.com/mdn/browser-compat-data">We&apos;re converting our compatibility data into a machine-readable JSON format</a></strong>.
            This compatibility table still uses the old format,
            because we haven&apos;t yet converted the data it contains.
            <strong><a href="/zh-CN/docs/MDN/Contribute/Structures/Compatibility_tables">Find out how you can help!</a></strong></div>

<div class="htab">
    <a id="AutoCompatibilityTable" name="AutoCompatibilityTable"></a>
    <ul>
        <li class="selected"><a>Desktop</a></li>
        <li><a>Mobile</a></li>
    </ul>
</div></div>

<div id="compat-desktop">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Feature</th>
   <th>Chrome</th>
   <th>Firefox (Gecko)</th>
   <th>Internet Explorer</th>
   <th>Opera</th>
   <th>Safari (WebKit)</th>
  </tr>
  <tr>
   <td>Basic support</td>
   <td>10.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/zh-CN/docs/Web/Guide/Prefixes">webkit</a></span></td>
   <td><a href="/en-US/Firefox/Releases/25">25.0</a> (25.0) </td>
   <td><span style="color: #f00;">未实现</span></td>
   <td>15.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/zh-CN/docs/Web/Guide/Prefixes">webkit</a></span><br>
    22 (unprefixed)</td>
   <td>6.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/zh-CN/docs/Web/Guide/Prefixes">webkit</a></span></td>
  </tr>
 </tbody>
</table>
</div>

<div id="compat-mobile">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Feature</th>
   <th>Android</th>
   <th>Firefox Mobile (Gecko)</th>
   <th>Firefox OS</th>
   <th>IE Mobile</th>
   <th>Opera Mobile</th>
   <th>Safari Mobile</th>
   <th>Chrome for Android</th>
  </tr>
  <tr>
   <td>Basic support</td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td>26.0</td>
   <td>1.2</td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td>33.0</td>
  </tr>
 </tbody>
</table>
</div>

<h2 id="See_also">See also</h2>

<ul>
 <li><a href="/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
</ul>
