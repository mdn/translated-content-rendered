---
title: 语音识别
slug: Web/API/语音识别
translation_of: Web/API/SpeechRecognition
---
<section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/zh-CN/docs/Web/API/语音识别"><code>语音识别</code></a></strong></li><li class="toggle"><details open><summary>Related pages for Web Speech API</summary><ol><li><a href="/zh-CN/docs/Web/API/SpeechGrammar"><code>SpeechGrammar</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechGrammarList"><code>SpeechGrammarList</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognition"><code>SpeechRecognition</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognitionAlternative"><code>SpeechRecognitionAlternative</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognitionError"><code>SpeechRecognitionError</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognitionEvent"><code>SpeechRecognitionEvent</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognitionResult"><code>SpeechRecognitionResult</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechRecognitionResultList"><code>SpeechRecognitionResultList</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechSynthesis"><code>SpeechSynthesis</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechSynthesisErrorEvent"><code>SpeechSynthesisErrorEvent</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechSynthesisEvent"><code>SpeechSynthesisEvent</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechSynthesisUtterance"><code>SpeechSynthesisUtterance</code></a></li><li><a href="/zh-CN/docs/Web/API/SpeechSynthesisVoice"><code>SpeechSynthesisVoice</code></a></li></ol></details></li></ol></section><div class="experimental indicator-warning notecard">
    <p><strong>这是一个实验中的功能</strong><br>此功能某些浏览器尚在开发中，请参考<a href="#Browser_compatibility">浏览器兼容性表格</a>以得到在不同浏览器中适合使用的前缀。由于该功能对应的标准文档可能被重新修订，所以在未来版本的浏览器中该功能的语法和行为可能随之改变。</p>
</div>

<p>The <strong><code>SpeechRecognition</code></strong> interface of the <a href="/en-US/docs/Web/API/Web_Speech_API">Web Speech API</a> is the controller interface for the recognition service; this also handles the <a href="/zh-CN/docs/Web/API/SpeechRecognitionEvent"><code>SpeechRecognitionEvent</code></a> sent from the recognition service.</p>

<div class="note notecard">
<p><strong>Note</strong>: On Chrome, using Speech Recognition on a web page involves a server-based recognition engine. Your audio is sent to a web service for recognition processing, so it won&apos;t work offline.</p>
</div>

<h2 id="Constructor">Constructor</h2>

<dl>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/SpeechRecognition"><code>SpeechRecognition.SpeechRecognition()</code></a></dt>
 <dd>Creates a new <code>SpeechRecognition</code> object.</dd>
</dl>

<h2 id="Properties">Properties</h2>

<p><em><code>SpeechRecognition</code> also inherits properties from its parent interface, <a href="/zh-CN/docs/Web/API/EventTarget"><code>EventTarget</code></a>.</em></p>

<dl>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/grammars"><code>SpeechRecognition.grammars</code></a></dt>
 <dd>Returns and sets a collection of <a href="/zh-CN/docs/Web/API/SpeechGrammar"><code>SpeechGrammar</code></a> objects that represent the grammars that will be understood by the current <code>SpeechRecognition</code>.</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/lang"><code>SpeechRecognition.lang</code></a></dt>
 <dd>Returns and sets the language of the current <code>SpeechRecognition</code>. If not specified, this defaults to the HTML <code><a href="/zh-CN/docs/Web/HTML/Element/html#attr-lang">lang</a></code> attribute value, or the user agent&apos;s language setting if that isn&apos;t set either.</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/continuous"><code>SpeechRecognition.continuous</code></a></dt>
 <dd>Controls whether continuous results are returned for each recognition, or only a single result. Defaults to single (<code>false</code>.)</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/interimResults"><code>SpeechRecognition.interimResults</code></a></dt>
 <dd>Controls whether interim results should be returned (<code>true</code>) or not (<code>false</code>.) Interim results are results that are not yet final (e.g. the <a href="/zh-CN/docs/Web/API/SpeechRecognitionResult/isFinal"><code>SpeechRecognitionResult.isFinal</code></a> property is <code>false</code>.)</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/maxAlternatives"><code>SpeechRecognition.maxAlternatives</code></a></dt>
 <dd>Sets the maximum number of <a href="/zh-CN/docs/Web/API/SpeechRecognitionAlternative"><code>SpeechRecognitionAlternative</code></a>s provided per result. The default value is 1.</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/serviceURI"><code>SpeechRecognition.serviceURI</code></a></dt>
 <dd>Specifies the location of the speech recognition service used by the current <code>SpeechRecognition</code> to handle the actual recognition. The default is the user agent&apos;s default speech service.</dd>
</dl>

<dl>
</dl>

<h2 id="Methods">Methods</h2>

<p><em><code>SpeechRecognition</code> also inherits methods from its parent interface, <a href="/zh-CN/docs/Web/API/EventTarget"><code>EventTarget</code></a>.</em></p>

<dl>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/abort"><code>SpeechRecognition.abort()</code></a></dt>
 <dd>Stops the speech recognition service from listening to incoming audio, and doesn&apos;t attempt to return a <a href="/zh-CN/docs/Web/API/SpeechRecognitionResult"><code>SpeechRecognitionResult</code></a>.</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/start"><code>SpeechRecognition.start()</code></a></dt>
 <dd>Starts the speech recognition service listening to incoming audio with intent to recognize grammars associated with the current <code>SpeechRecognition</code>.</dd>
 <dt><a href="/zh-CN/docs/Web/API/SpeechRecognition/stop"><code>SpeechRecognition.stop()</code></a></dt>
 <dd>Stops the speech recognition service from listening to incoming audio, and attempts to return a <a href="/zh-CN/docs/Web/API/SpeechRecognitionResult"><code>SpeechRecognitionResult</code></a> using the audio captured so far.</dd>
</dl>

<h2 id="Events">Events</h2>

<p>Listen to these events using <code><a href="/en-US/docs/Web/API/EventTarget/addEventListener">addEventListener()</a></code> or by assigning an event listener to the <code>on<em>eventname</em></code> property of this interface.</p>

<dl>
 <dt><a href="/en-US/docs/Web/API/SpeechRecognition/audiostart_event"><code>audiostart</code></a></dt>
 <dd>Fired when the user agent has started to capture audio.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onaudiostart">onaudiostart</a></code> property.</dd>
 <dt><a href="/en-US/docs/Web/API/SpeechRecognition/audioend_event"><code>audioend</code></a></dt>
 <dd>Fired when the user agent has finished capturing audio.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onaudioend">onaudioend</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/end_event">end</a></code></dt>
 <dd>Fired when the speech recognition service has disconnected.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onend">onend</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/error_event">error</a></code></dt>
 <dd>Fired when a speech recognition error occurs.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onerror">onerror</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/nomatch_event">nomatch</a></code></dt>
 <dd>Fired when the speech recognition service returns a final result with no significant recognition. This may involve some degree of recognition, which doesn&apos;t meet or exceed the <a href="/zh-CN/docs/Web/API/SpeechRecognitionAlternative/confidence"><code>confidence</code></a> threshold.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onnomatch">onnomatch</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/result_event">result</a></code></dt>
 <dd>Fired when the speech recognition service returns a result — a word or phrase has been positively recognized and this has been communicated back to the app.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onresult">onresult</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/soundstart_event">soundstart</a></code></dt>
 <dd>Fired when any sound — recognisable speech or not — has been detected.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onsoundstart">onsoundstart</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/soundend_event">soundend</a></code></dt>
 <dd>Fired when any sound — recognisable speech or not — has stopped being detected.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onsoundend">onsoundend</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/speechstart_event">speechstart</a></code></dt>
 <dd>Fired when sound that is recognised by the speech recognition service as speech has been detected.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onspeechstart">onspeechstart</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/speechend_event">speechend</a></code></dt>
 <dd>Fired when speech recognised by the speech recognition service has stopped being detected.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechRecognition/onspeechend">onspeechend</a></code> property.</dd>
 <dt><code><a href="/en-US/docs/Web/API/SpeechRecognition/start_event">start</a></code></dt>
 <dd>Fired when the speech recognition service has begun listening to incoming audio with intent to recognize grammars associated with the current <code>SpeechRecognition</code>.<br>
 Also available via the <code><a href="/en-US/docs/Web/API/SpeechSynthesisUtterance/onstart">onstart</a></code> property.</dd>
</dl>

<h2 id="Examples">Examples</h2>

<p>In our simple <a href="https://github.com/mdn/web-speech-api/tree/master/speech-color-changer">Speech color changer</a> example, we create a new <code>SpeechRecognition</code> object instance using the <a href="/zh-CN/docs/Web/API/SpeechRecognition/SpeechRecognition"><code>SpeechRecognition()</code></a> constructor, create a new <a href="/zh-CN/docs/Web/API/SpeechGrammarList"><code>SpeechGrammarList</code></a>, and set it to be the grammar that will be recognised by the <code>SpeechRecognition</code> instance using the <a href="/zh-CN/docs/Web/API/SpeechRecognition/grammars"><code>SpeechRecognition.grammars</code></a> property.</p>

<p>After some other values have been defined, we then set it so that the recognition service starts when a click event occurs (see <a href="/zh-CN/docs/Web/API/SpeechRecognition/start"><code>SpeechRecognition.start()</code></a>.) When a result has been successfully recognised, the <a href="/zh-CN/docs/Web/API/SpeechRecognition/onresult"><code>SpeechRecognition.onresult</code></a> handler fires,  we extract the color that was spoken from the event object, and then set the background color of the <a href="/zh-CN/docs/Web/HTML/Element/html" title="HTML &lt;html&gt; 元素 表示一个HTML文档的根（顶级元素），所以它也被称为根元素。所有其他元素必须是此元素的后代。"><code>&lt;html&gt;</code></a> element to that colour.</p>

<pre class="brush: js notranslate">var grammar = &apos;#JSGF V1.0; grammar colors; public &lt;color&gt; = aqua | azure | beige | bisque | black | blue | brown | chocolate | coral | crimson | cyan | fuchsia | ghostwhite | gold | goldenrod | gray | green | indigo | ivory | khaki | lavender | lime | linen | magenta | maroon | moccasin | navy | olive | orange | orchid | peru | pink | plum | purple | red | salmon | sienna | silver | snow | tan | teal | thistle | tomato | turquoise | violet | white | yellow ;&apos;
var recognition = new SpeechRecognition();
var speechRecognitionList = new SpeechGrammarList();
speechRecognitionList.addFromString(grammar, 1);
recognition.grammars = speechRecognitionList;
//recognition.continuous = false;
recognition.lang = &apos;en-US&apos;;
recognition.interimResults = false;
recognition.maxAlternatives = 1;

var diagnostic = document.querySelector(&apos;.output&apos;);
var bg = document.querySelector(&apos;html&apos;);

document.body.onclick = function() {
  recognition.start();
  console.log(&apos;Ready to receive a color command.&apos;);
}

recognition.onresult = function(event) {
  var color = event.results[0][0].transcript;
  diagnostic.textContent = &apos;Result received: &apos; + color;
  bg.style.backgroundColor = color;
}</pre>

<h2 id="Specifications">Specifications</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Specification</th>
   <th scope="col">Status</th>
   <th scope="col">Comment</th>
  </tr>
  <tr>
   <td><a class="external" href="https://wicg.github.io/speech-api/#speechreco-section" hreflang="en" lang="en">Web Speech API<br><small lang="zh-CN">SpeechRecognition</small></a></td>
   <td><span class="spec-Draft">Draft</span></td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="Browser_compatibility">Browser compatibility</h2>

<div class="hidden">The compatibility table on this page is generated from structured data. If you&apos;d like to contribute to the data, please check out <a href="https://github.com/mdn/browser-compat-data">https://github.com/mdn/browser-compat-data</a> and send us a pull request.</div>

<div class="bc-data" id="bcd:api.SpeechRecognition"></div>

<h2 id="See_also">See also</h2>

<ul>
 <li><a href="/en-US/docs/Web/API/Web_Speech_API">Web Speech API</a></li>
</ul>
