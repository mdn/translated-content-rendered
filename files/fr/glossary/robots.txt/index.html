---
title: Robots.txt
slug: Glossaire/Robots.txt
tags:
  - Glossaire
  - Infrastructure
translation_of: Glossary/Robots.txt
---
<p>Robots.txt est un fichier qui est habituellement placé à la racine d&apos;un site web. Il détermine si les <a href="/fr/docs/Glossaire/Robot_d_indexation" class="glossaryLink" title="robots d&apos;indexation : Un robot d&apos;indexation est un programme, souvent appelé bot ou robot, qui parcourt de manière systématique le Web pour collecter des données à partir des pages web. Les moteurs de recherche utilisent généralement des robots d&apos;indexation pour construire leurs index.">robots d&apos;indexation</a> ont ou non l&apos;autorisation d&apos;accéder au site web.</p>

<p>Par exemple, l&apos;administrateur d&apos;un site peut interdire aux robots d&apos;indexation de parcourir un certain dossier (et tous les fichiers contenus à l&apos;intérieur) ou de parcourir un fichier spécifique, généralement pour empêcher ces fichiers d&apos;être indexés par d&apos;autres moteurs de recherche.</p>

<h2 id="Pour_approfondir">Pour approfondir</h2>

<h3 id="Culture_générale">Culture générale</h3>

<ul>
 <li><a href="https://fr.wikipedia.org/wiki/Protocole_d&apos;exclusion_des_robots">Robots.txt</a> sur Wikipédia</li>
</ul>
